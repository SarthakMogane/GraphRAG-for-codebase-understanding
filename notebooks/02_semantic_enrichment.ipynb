{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Semantic Enrichment & Vector Search\n",
    "## Adding Intelligence to Your Code Graph\n",
    "\n",
    "In this notebook, we'll:\n",
    "1. Load the Week 1 structural graph\n",
    "2. Add LLM-generated summaries\n",
    "3. Create vector embeddings\n",
    "4. Build FAISS index\n",
    "5. Test semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from utils.llm_client import LangChainClient\n",
    "from indexing.semantic_enrichment import SemanticEnricher\n",
    "from indexing.vector_store import VectorStore\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Week 1 Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the structural graph from Week 1\n",
    "graph_path = '../data/graphs/code_graph.pkl'\n",
    "\n",
    "with open(graph_path, 'rb') as f:\n",
    "    graph = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded graph: {graph.number_of_nodes()} nodes, {graph.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a sample node BEFORE enrichment\n",
    "sample_node = list(graph.nodes(data=True))[5]\n",
    "node_id, attrs = sample_node\n",
    "\n",
    "print(f\"Node: {attrs['name']} ({attrs['type']})\")\n",
    "print(f\"\\nCurrent attributes:\")\n",
    "for key, value in attrs.items():\n",
    "    if key != 'code':\n",
    "        print(f\"  {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"  code: {len(value)} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Semantic Enrichment with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM client\n",
    "llm_client = LangChainClient(\n",
    "    provider='google',  # or 'openai', 'anthropic'\n",
    "    model_name='gemini-2.0-flash-exp'\n",
    ")\n",
    "\n",
    "print(f\"âœ“ LLM client initialized: {llm_client.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test enrichment on a single node first\n",
    "enricher = SemanticEnricher(llm_client=llm_client)\n",
    "\n",
    "# Pick a function node\n",
    "test_node = None\n",
    "for node_id, attrs in graph.nodes(data=True):\n",
    "    if attrs.get('type') == 'function' and len(attrs.get('code', '')) > 50:\n",
    "        test_node = (node_id, attrs)\n",
    "        break\n",
    "\n",
    "if test_node:\n",
    "    node_id, attrs = test_node\n",
    "    print(f\"Testing enrichment on: {attrs['name']}\\n\")\n",
    "    \n",
    "    enriched = enricher.enrich_single(node_id, attrs)\n",
    "    \n",
    "    print(\"âœ“ Enrichment result:\")\n",
    "    print(f\"  Summary: {enriched.summary}\")\n",
    "    print(f\"  Description: {enriched.description}\")\n",
    "    print(f\"  Tags: {', '.join(enriched.tags)}\")\n",
    "    print(f\"  Complexity: {enriched.complexity}\")\n",
    "    print(f\"  Purpose: {enriched.purpose}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrich the entire graph (this will take a few minutes)\n",
    "print(\"Enriching all nodes... (this may take 2-5 minutes)\\n\")\n",
    "\n",
    "enriched_graph = enricher.enrich_graph(graph, skip_existing=True)\n",
    "\n",
    "print(\"\\nâœ“ Enrichment complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show enrichment statistics\n",
    "stats = enricher.get_enrichment_stats(enriched_graph)\n",
    "\n",
    "print(f\"\\n=== Enrichment Statistics ===\")\n",
    "print(f\"Total nodes: {stats['total_nodes']}\")\n",
    "print(f\"Enriched: {stats['enriched_nodes']} ({stats['enrichment_rate']:.1%})\")\n",
    "print(f\"Unique tags: {stats['total_unique_tags']}\")\n",
    "\n",
    "print(f\"\\nTop tags:\")\n",
    "for tag, count in stats['top_tags'][:10]:\n",
    "    print(f\"  {tag}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize tag distribution\n",
    "tag_data = stats['top_tags'][:15]\n",
    "tags, counts = zip(*tag_data)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(tags, counts, color='skyblue')\n",
    "plt.xlabel('Count')\n",
    "plt.title('Top 15 Code Tags')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM caching enabled\n",
    "print(\"\\n=== LLM Configuration ===\")\n",
    "print(f\"Provider: {llm_client.provider}\")\n",
    "print(f\"Model: {llm_client.model_name}\")\n",
    "print(f\"Cache: Enabled (LangChain InMemoryCache)\")\n",
    "print(f\"Note: LLM API usage tracked automatically by the provider\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Vector Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vector store\n",
    "vector_store = VectorStore(\n",
    "    provider='huggingface',  # Local, free, fast\n",
    "    model_name='all-MiniLM-L6-v2',  # Fast and good quality\n",
    "    index_type='Flat'   # Exact search\n",
    ")\n",
    "\n",
    "print(f\"Vector store initialized:\")\n",
    "print(f\"  Embedding dim: {vector_store.embedding_dim}\")\n",
    "print(f\"  Index type: {vector_store.index_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build index from enriched graph\n",
    "print(\"Building vector index...\\n\")\n",
    "\n",
    "vector_store.build_from_graph(\n",
    "    enriched_graph,\n",
    "    text_field='combined',  # Combines code, summary, tags\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Vector index built: {len(vector_store.node_ids)} vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_search_results(query, results):\n",
    "    \"\"\"Pretty print search results\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"{i}. {result.name} ({result.type})\")\n",
    "        print(f\"   Score: {result.score:.3f}\")\n",
    "        if result.summary:\n",
    "            print(f\"   Summary: {result.summary}\")\n",
    "        if result.tags:\n",
    "            print(f\"   Tags: {', '.join(result.tags[:5])}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test various queries\n",
    "test_queries = [\n",
    "    \"function that validates user input\",\n",
    "    \"code for reading and parsing data\",\n",
    "    \"database connection or storage\",\n",
    "    \"configuration and settings\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    results = vector_store.search(query, top_k=3)\n",
    "    display_search_results(query, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive search\n",
    "def interactive_search():\n",
    "    print(\"\\nðŸ” Enter queries (or 'quit' to exit):\\n\")\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"Query > \").strip()\n",
    "        \n",
    "        if query.lower() in ['quit', 'exit', 'q']:\n",
    "            break\n",
    "        \n",
    "        if not query:\n",
    "            continue\n",
    "        \n",
    "        results = vector_store.search(query, top_k=5)\n",
    "        display_search_results(query, results)\n",
    "\n",
    "# Uncomment to use:\n",
    "# interactive_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Search Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare score distributions\n",
    "sample_queries = [\n",
    "    \"validation function\",\n",
    "    \"data processing\",\n",
    "    \"configuration management\"\n",
    "]\n",
    "\n",
    "all_scores = []\n",
    "query_labels = []\n",
    "\n",
    "for query in sample_queries:\n",
    "    results = vector_store.search(query, top_k=10)\n",
    "    scores = [r.score for r in results]\n",
    "    all_scores.extend(scores)\n",
    "    query_labels.extend([query[:20]] * len(scores))\n",
    "\n",
    "# Plot\n",
    "df = pd.DataFrame({'Query': query_labels, 'Score': all_scores})\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df, x='Query', y='Score')\n",
    "plt.title('Search Score Distribution by Query Type')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find similar nodes\n",
    "def find_and_display_similar(node_name, top_k=5):\n",
    "    \"\"\"Find nodes similar to a given node\"\"\"\n",
    "    \n",
    "    # Find node ID\n",
    "    target_node_id = None\n",
    "    for node_id, attrs in enriched_graph.nodes(data=True):\n",
    "        if attrs.get('name') == node_name:\n",
    "            target_node_id = node_id\n",
    "            print(f\"Found: {attrs['name']} ({attrs['type']})\")\n",
    "            print(f\"Summary: {attrs.get('summary', 'N/A')}\\n\")\n",
    "            break\n",
    "    \n",
    "    if not target_node_id:\n",
    "        print(f\"Node '{node_name}' not found\")\n",
    "        return\n",
    "    \n",
    "    # Find similar\n",
    "    similar = vector_store.find_similar_nodes(target_node_id, top_k=top_k)\n",
    "    \n",
    "    print(f\"Similar nodes:\\n\")\n",
    "    for i, result in enumerate(similar, 1):\n",
    "        print(f\"{i}. {result.name} ({result.type}) - Score: {result.score:.3f}\")\n",
    "        if result.summary:\n",
    "            print(f\"   {result.summary}\")\n",
    "        print()\n",
    "\n",
    "# Try it\n",
    "find_and_display_similar('save_to_file', top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save enriched graph\n",
    "enriched_path = '../data/graphs/code_graph_enriched.pkl'\n",
    "with open(enriched_path, 'wb') as f:\n",
    "    pickle.dump(enriched_graph, f)\n",
    "print(f\"âœ“ Enriched graph saved: {enriched_path}\")\n",
    "\n",
    "# Save vector store\n",
    "vector_path = '../data/graphs/vector_store'\n",
    "vector_store.save(vector_path)\n",
    "print(f\"âœ“ Vector store saved: {vector_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Week 2 Complete! You now have:\n",
    "- âœ… LLM-generated summaries for all code entities\n",
    "- âœ… Domain tags and complexity ratings\n",
    "- âœ… Vector embeddings (384 dimensions)\n",
    "- âœ… FAISS index for fast similarity search\n",
    "- âœ… Semantic search capability\n",
    "\n",
    "**Week 3 Preview:**\n",
    "- Community detection (Louvain algorithm)\n",
    "- Hierarchical summarization\n",
    "- Global query support\n",
    "- Query classification (global vs local)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
