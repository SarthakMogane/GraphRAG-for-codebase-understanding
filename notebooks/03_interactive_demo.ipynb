{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG Codebase Understanding - Interactive Demo\n",
    "\n",
    "This notebook demonstrates the GraphRAG system for code understanding.\n",
    "\n",
    "## What you'll learn:\n",
    "1. How to index a GitHub repository\n",
    "2. How to query the codebase using natural language\n",
    "3. How different retrieval strategies work\n",
    "4. How to evaluate system performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: d:\\kaggle_project\\GraphRAG\n",
      "SRC_DIR: d:\\kaggle_project\\GraphRAG\\src\n",
      "Loading .env from: d:\\kaggle_project\\GraphRAG\\.env\n",
      "GOOGLE_API_KEY from env: AIzaSyDHDF3uw3wUbqUg2mODysokzqhxXPWoHAI\n",
      "NEO4J_PASSWORD from env: graphrag2025\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1) Project root (.. from notebooks/)\n",
    "PROJECT_ROOT = Path.cwd().parent  # -> d:\\kaggle_project\\GraphRAG\n",
    "SRC_DIR = PROJECT_ROOT / \"src\"\n",
    "\n",
    "# 2) Add project root to sys.path (so `src.` imports work)\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"SRC_DIR:\", SRC_DIR)\n",
    "\n",
    "# 3) Explicitly load .env from project root\n",
    "env_path = PROJECT_ROOT / \".env\"\n",
    "print(\"Loading .env from:\", env_path)\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# 4) Debug: check that env vars are actually visible\n",
    "print(\"GOOGLE_API_KEY from env:\", os.getenv(\"GOOGLE_API_KEY\"))\n",
    "print(\"NEO4J_PASSWORD from env:\", os.getenv(\"NEO4J_PASSWORD\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for LlmAgent\ntools\n  Input should be a valid list [type=list_type, input_value=<bound method ParserAgent... at 0x000002341F96BE90>>, input_type=method]\n    For further information visit https://errors.pydantic.dev/2.12/v/list_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01masyncio\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01morchestrator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m orchestrator\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparser_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parser_agent\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneo4j_tools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m neo4j_manager\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\kaggle_project\\GraphRAG\\src\\agents\\orchestrator.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mloguru\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logger\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenerativeai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgenai\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparser_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parser_agent\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01msearch_traversal_synthesis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     search_agent, traversal_agent, synthesis_agent\n\u001b[32m      8\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcode_entities\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     QueryIntent, RetrievalStrategy, GraphRAGResponse, SearchResult\n\u001b[32m     11\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\kaggle_project\\GraphRAG\\src\\agents\\parser_agent.py:336\u001b[39m\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m hashlib.md5(unique_str.encode()).hexdigest()[:\u001b[32m16\u001b[39m]\n\u001b[32m    335\u001b[39m \u001b[38;5;66;03m# Global instance\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m parser_agent = \u001b[43mParserAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\kaggle_project\\GraphRAG\\src\\agents\\parser_agent.py:33\u001b[39m, in \u001b[36mParserAgent.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mself\u001b[39m.description = \u001b[33m\"\u001b[39m\u001b[33mParses code repositories and builds knowledge graphs\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Register tools\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mself\u001b[39m.tools = [\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[43mLlmAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclone_repository\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mClone a GitHub repository\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclone_repository\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     38\u001b[39m     LlmAgent(\n\u001b[32m     39\u001b[39m         name=\u001b[33m\"\u001b[39m\u001b[33mparse_repository\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     40\u001b[39m         description=\u001b[33m\"\u001b[39m\u001b[33mParse all source files in repository\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     41\u001b[39m         tools=[\u001b[38;5;28mself\u001b[39m.parse_repository]\n\u001b[32m     42\u001b[39m     ),\n\u001b[32m     43\u001b[39m     LlmAgent(\n\u001b[32m     44\u001b[39m         name=\u001b[33m\"\u001b[39m\u001b[33mbuild_knowledge_graph\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     45\u001b[39m         description=\u001b[33m\"\u001b[39m\u001b[33mBuild Neo4j knowledge graph from parsed code\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     46\u001b[39m         tools=[\u001b[38;5;28mself\u001b[39m.build_knowledge_graph]\n\u001b[32m     47\u001b[39m     ),\n\u001b[32m     48\u001b[39m     LlmAgent(\n\u001b[32m     49\u001b[39m         name=\u001b[33m\"\u001b[39m\u001b[33mgenerate_embeddings\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     50\u001b[39m         description=\u001b[33m\"\u001b[39m\u001b[33mGenerate embeddings for code entities\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     51\u001b[39m         tools=[\u001b[38;5;28mself\u001b[39m.generate_embeddings]\n\u001b[32m     52\u001b[39m     )\n\u001b[32m     53\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\kaggle_project\\GraphRAG\\myenv\\Lib\\site-packages\\pydantic\\main.py:250\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    249\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    252\u001b[39m     warnings.warn(\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    256\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    257\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for LlmAgent\ntools\n  Input should be a valid list [type=list_type, input_value=<bound method ParserAgent... at 0x000002341F96BE90>>, input_type=method]\n    For further information visit https://errors.pydantic.dev/2.12/v/list_type"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "from src.agents.orchestrator import orchestrator\n",
    "from src.agents.parser_agent import parser_agent\n",
    "from src.tools.neo4j_operations import neo4j_manager\n",
    "from src.utils.metrics import GraphRAGEvaluator\n",
    "from src.models.entities import QueryIntent, RetrievalStrategy\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import sys\n",
    "# sys.path.append('../src')\n",
    "\n",
    "# import asyncio\n",
    "# from agents.orchestrator import orchestrator\n",
    "# from agents.parser_agent import parser_agent\n",
    "# from tools.neo4j_tools import neo4j_manager\n",
    "# from utils.metrics import GraphRAGEvaluator\n",
    "# from models.code_entities import QueryIntent, RetrievalStrategy\n",
    "\n",
    "# print(\"‚úÖ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Index a Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Indexing: https://github.com/donnemartin/data-science-ipython-notebooks\n",
      "This will take a few minutes...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose a repository to index\n",
    "REPO_URL = \"https://github.com/donnemartin/data-science-ipython-notebooks\"\n",
    "BRANCH = \"master\"\n",
    "\n",
    "print(f\"üì¶ Indexing: {REPO_URL}\")\n",
    "print(\"This will take a few minutes...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'neo4j_manager' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Clear existing data (optional)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mneo4j_manager\u001b[49m.clear_database()\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müóëÔ∏è  Database cleared\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'neo4j_manager' is not defined"
     ]
    }
   ],
   "source": [
    "# Clear existing data (optional)\n",
    "neo4j_manager.clear_database()\n",
    "print(\"üóëÔ∏è  Database cleared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index the repository\n",
    "result = await orchestrator.index_repository(\n",
    "    repo_url=REPO_URL,\n",
    "    branch=BRANCH\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Indexing complete!\")\n",
    "print(f\"Files parsed: {result['parse']['parsed_files']}\")\n",
    "print(f\"Functions found: {result['parse']['total_functions']}\")\n",
    "print(f\"Classes found: {result['parse']['total_classes']}\")\n",
    "print(f\"Graph nodes: {result['graph']['nodes_created']}\")\n",
    "print(f\"Embeddings: {result['embeddings']['embeddings_created']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Query the Codebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example queries\n",
    "queries = [\n",
    "    \"What functions handle data preprocessing?\",\n",
    "    \"Show me functions related to machine learning models\",\n",
    "    \"Where is pandas used in the codebase?\",\n",
    "    \"What are the main data visualization functions?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run first query\n",
    "query = queries[0]\n",
    "\n",
    "print(f\"‚ùì Query: {query}\\n\")\n",
    "\n",
    "response = await orchestrator.query(\n",
    "    query,\n",
    "    top_k=10,\n",
    "    max_depth=2\n",
    ")\n",
    "\n",
    "print(f\"Intent: {response.intent.value}\")\n",
    "print(f\"Strategy: {response.strategy.value}\")\n",
    "print(f\"Confidence: {response.confidence:.1%}\")\n",
    "print(f\"Retrieved nodes: {len(response.retrieved_nodes)}\\n\")\n",
    "\n",
    "print(\"üìù ANSWER:\")\n",
    "print(\"-\" * 80)\n",
    "print(response.answer)\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View retrieved context\n",
    "print(\"üìö Top Retrieved Functions:\\n\")\n",
    "\n",
    "for i, node in enumerate(response.retrieved_nodes[:5], 1):\n",
    "    print(f\"{i}. {node.name}\")\n",
    "    print(f\"   File: {node.file_path}\")\n",
    "    print(f\"   Score: {node.score:.3f}\")\n",
    "    print(f\"   Source: {node.source}\")\n",
    "    if node.docstring:\n",
    "        print(f\"   Doc: {node.docstring[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Compare Retrieval Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different strategies\n",
    "test_query = \"What functions handle file I/O?\"\n",
    "\n",
    "strategies = [\n",
    "    RetrievalStrategy.VECTOR_ONLY,\n",
    "    RetrievalStrategy.GRAPH_ONLY,\n",
    "    RetrievalStrategy.HYBRID,\n",
    "    RetrievalStrategy.SEMANTIC_THEN_GRAPH\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for strategy in strategies:\n",
    "    print(f\"\\nüîç Testing {strategy.value}...\")\n",
    "    \n",
    "    # For this demo, we'd need to modify the orchestrator to accept strategy override\n",
    "    # Simplified version:\n",
    "    response = await orchestrator.query(test_query, top_k=10, max_depth=2)\n",
    "    \n",
    "    results[strategy.value] = {\n",
    "        'nodes_retrieved': len(response.retrieved_nodes),\n",
    "        'confidence': response.confidence,\n",
    "        'answer_length': len(response.answer)\n",
    "    }\n",
    "    \n",
    "    print(f\"   Nodes: {results[strategy.value]['nodes_retrieved']}\")\n",
    "    print(f\"   Confidence: {results[strategy.value]['confidence']:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "df = pd.DataFrame(results).T.reset_index()\n",
    "df.columns = ['Strategy', 'Nodes Retrieved', 'Confidence', 'Answer Length']\n",
    "\n",
    "fig = px.bar(\n",
    "    df, \n",
    "    x='Strategy', \n",
    "    y='Nodes Retrieved',\n",
    "    title='Nodes Retrieved by Strategy',\n",
    "    color='Confidence',\n",
    "    color_continuous_scale='Viridis'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Evaluate System Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluator\n",
    "evaluator = GraphRAGEvaluator()\n",
    "\n",
    "# Define ground truth test cases\n",
    "test_cases = [\n",
    "    {\n",
    "        'query': 'What functions handle data cleaning?',\n",
    "        'expected_nodes': ['clean_data', 'remove_nulls', 'normalize'],\n",
    "        'expected_answer': 'Data cleaning functions include...'\n",
    "    },\n",
    "    {\n",
    "        'query': 'Where is matplotlib used?',\n",
    "        'expected_nodes': ['plot_graph', 'visualize_data'],\n",
    "        'expected_answer': 'Matplotlib is used for visualization...'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üß™ Running evaluation...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "for test in test_cases:\n",
    "    response = await orchestrator.query(test['query'], top_k=10)\n",
    "    \n",
    "    retrieved_node_names = [node.name for node in response.retrieved_nodes]\n",
    "    \n",
    "    evaluator.add_evaluation(\n",
    "        query=test['query'],\n",
    "        expected_answer=test['expected_answer'],\n",
    "        generated_answer=response.answer,\n",
    "        retrieved_nodes=retrieved_node_names,\n",
    "        expected_nodes=test['expected_nodes']\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Evaluated: {test['query']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results\n",
    "evaluator.print_report()\n",
    "\n",
    "# Save results\n",
    "evaluator.save_results('../data/evaluation/results.json')\n",
    "print(\"\\nüíæ Results saved to data/evaluation/results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Explore the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Neo4j directly\n",
    "query = \"\"\"\n",
    "MATCH (f:Function)\n",
    "RETURN f.name as name, f.file_path as file, size(f.code) as code_size\n",
    "ORDER BY code_size DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "results = neo4j_manager.execute_cypher(query)\n",
    "\n",
    "print(\"üìä Largest Functions:\\n\")\n",
    "for i, r in enumerate(results, 1):\n",
    "    print(f\"{i}. {r['name']} ({r['file']})\")\n",
    "    print(f\"   Code size: {r['code_size']} characters\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most-called functions\n",
    "query = \"\"\"\n",
    "MATCH (f:Function)<-[r:CALLS]-(:Function)\n",
    "WITH f, count(r) as call_count\n",
    "RETURN f.name as name, f.file_path as file, call_count\n",
    "ORDER BY call_count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "results = neo4j_manager.execute_cypher(query)\n",
    "\n",
    "print(\"üìû Most Called Functions:\\n\")\n",
    "for i, r in enumerate(results, 1):\n",
    "    print(f\"{i}. {r['name']} ({r['file']})\")\n",
    "    print(f\"   Called by {r['call_count']} functions\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You've learned:\n",
    "- ‚úÖ How to index a repository into a knowledge graph\n",
    "- ‚úÖ How to query code using natural language\n",
    "- ‚úÖ Different retrieval strategies and their trade-offs\n",
    "- ‚úÖ How to evaluate system performance\n",
    "- ‚úÖ How to explore the graph database\n",
    "\n",
    "**Next steps:**\n",
    "- Try indexing your own repository\n",
    "- Experiment with different query strategies\n",
    "- Customize the graph schema for your needs\n",
    "- Add support for more programming languages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
